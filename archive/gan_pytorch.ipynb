{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import DataFrame, concat\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import parallel_backend\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24ecab0a810>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(111)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Harvard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_2464\\1621371962.py:7: DtypeWarning: Columns (24,157,481,483,484,486,487,503) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  harvard = pd.read_csv('../harvard/data/dropped_variables.csv', sep=\";\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values per variable\n",
      "total records: 150\n",
      "age                             0\n",
      "asthma                          9\n",
      "bmi                             7\n",
      "chronic_kidney_disease          9\n",
      "cough                           0\n",
      "diabetes                        9\n",
      "gender                          0\n",
      "gold                           28\n",
      "heart_failure                   9\n",
      "hospitalization                 1\n",
      "hypertension                    8\n",
      "icu                             1\n",
      "inhaler                         0\n",
      "ischemic_heart_disease          9\n",
      "mmrc                            0\n",
      "percent_fev1_pred              31\n",
      "pill_for_exa                    0\n",
      "smoker                          0\n",
      "sputum                          0\n",
      "target                          0\n",
      "two_exacerbations_last_year     0\n",
      "waking_up_at_night              0\n",
      "wheezing                        1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target = 'fclinra08'\n",
    "\n",
    "# missing: gold stage, cough, sputum, wheeze, baseline fev1, baseline fev1% predicted, symptoms wake you up at night, 2 ore more exacerbations in the last year, asthma, needs help with daily activities, chronic kidney disease, icu last year, hospitalized last year, smoker, pill for exa, inhaler\n",
    "relevant_vars = ['dem02', 'dem03', 'bclinra01', 'bclinra02', 'bclinpt04', 'bclinpt15', 'mmrc', 'bclinpt07', 'bclinpt34',  'bclinpt28',  'login', 'bclinpt19', 'bclinpt08','bclinpt09','bclinpt38', 'bclinpt32','bclinra11','bclinra07','psqi09','sgrq02','sgrq03', 'exact4', 'exact3', 'sgrq05','sgrq09', 'bclinra101', 'bclinra202c_2', 'bclinra202c_5', 'psqi06', 'bclinpt14','SRPSAT49_Bank','bclinpt11' ,'bclinpt26', 'bclinpt24','bclinpt43', 'bclinpt44','bclinpt45','bclinra06','bclinra06_1024','bclinra06_512','bclinra06_256','bclinra06_128','bclinra06_64','bclinra06_32','bclinra06_16','bclinra06_8','bclinra06_4','bclinra06_2','bclinra06_1', 'exact2','bclinpt22', 'bclinpt06', target] # (cancer), 'bclinpt36' fast breathing, \n",
    "\n",
    "# load harvard dataset\n",
    "harvard = pd.read_csv('./harvard/data/dropped_variables.csv', sep=\";\")\n",
    "harvard = harvard[relevant_vars]\n",
    "\n",
    "# change mmrc by starting at 0 instead of 1\n",
    "harvard['mmrc'] = harvard['mmrc'] - 1\n",
    "\n",
    "# make female 0 and male = 1\n",
    "harvard.loc[harvard['dem03'] == 2, 'dem03'] = 0\n",
    "harvard.loc[harvard['dem03'] == 1, 'dem03'] = 1\n",
    "\n",
    "# rename columns to common names with exaggerate\n",
    "harvard = harvard.rename(columns={\n",
    "    'dem02':'age', \n",
    "    'dem03': 'gender', \n",
    "    'bclinpt19': 'cancer', \n",
    "    'bclinpt04': 'hypertension', \n",
    "    'bclinpt15': 'diabetes', \n",
    "    'bclinpt07': 'heart_failure', \n",
    "    'bclinpt06': 'ischemic_heart_disease',\n",
    "    target: 'target', \n",
    "    'bclinra01': 'height', \n",
    "    'bclinra02': 'weight', \n",
    "    'bclinpt34': 'fever',  \n",
    "    'bclinpt08':'myocardial_infarct', \n",
    "    'bclinpt09':'stroke', \n",
    "    'bclinpt28':'dyspnoea', \n",
    "    'bclinpt36': 'fast_breathing', \n",
    "    'mmrc': 'mmrc', \n",
    "    'bclinpt22': 'prev_exacerb',\n",
    "    'bclinpt38': 'wheezing',\n",
    "    'sgrq05': 'wheezing_attacks',\n",
    "    'sgrq09': 'wheeze_morning', \n",
    "    'bclinpt32': 'sputum',\n",
    "    'sgrq03': 'bring_up_sputum',\n",
    "    'exact4': 'how_difficult_sputum',\n",
    "    'exact3': 'how_much_sputum',\n",
    "    'bclinra11': 'gold',\n",
    "    'exact2': 'cough_today',\n",
    "    'psqi09': 'cough_snore',\n",
    "    'sgrq02': 'cough_four_weeks',\n",
    "    'sgrq20': 'cough_hurts',\n",
    "    'sgrq21': 'cough_tired',\n",
    "    'bclinra101': 'fev1',\n",
    "    'bclinra202c_2': 'percent_fev1_pred',\n",
    "    'bclinra202c_5': 'percent_fev1_pred_2',\n",
    "    'psqi06': 'waking_up_at_night',\n",
    "    'bclinpt14': 'asthma',\n",
    "    'bclinpt11': 'chronic_kidney_disease',\n",
    "    'bclinpt26': 'icu_last_year',\n",
    "    'bclinpt24': 'hospitalizations_last_year',\n",
    "    'bclinpt43': 'medication_copd',\n",
    "    'bclinpt44': 'other_antibiotic',\n",
    "    'bclinpt45': 'other_medication',\n",
    "    'bclinra06': 'medication_copd_2',\n",
    "    'bclinra06_1024': 'other_copd_medication',\n",
    "    'bclinra06_512': 'qvar',\n",
    "    'bclinra06_256': 'azmacort',\n",
    "    'bclinra06_128': 'pulmicort',\n",
    "    'bclinra06_64': 'flovent',\n",
    "    'bclinra06_32': 'foradil',\n",
    "    'bclinra06_16': 'serevent',\n",
    "    'bclinra06_8': 'spiriva',\n",
    "    'bclinra06_4': 'combivent',\n",
    "    'bclinra06_2': 'atrovent',\n",
    "    'bclinra06_1': 'proventil',\n",
    " }) \n",
    "\n",
    "# generate the cough variable\n",
    "harvard['cough'] = 0\n",
    "\n",
    "# if cought_today is 2,3,4 or 5 set cough to 1\n",
    "harvard.loc[harvard['cough_today'] > 1, 'cough'] = 1\n",
    "\n",
    "# TODO check if we should use this variable. Seems like it might be related to snoring only\n",
    "# if cough_snore is > 1 set cough to 1\n",
    "# harvard.loc[harvard['cough_snore'] > 1, 'cough'] = 1\n",
    "# if cough_four_weeks is < 4 set cough to 1\n",
    "harvard.loc[harvard['cough_four_weeks'] < 4, 'cough'] = 1\n",
    "# drop cough_today, cough_snore, cough_four_weeks\n",
    "harvard = harvard.drop(columns=['cough_today', 'cough_snore', 'cough_four_weeks'], axis=1)\n",
    "\n",
    "# TODO we could use other sputum variables as well\n",
    "# if 'sputum' is 0 set it to 1 and the other way around\n",
    "harvard['sputum'] = 1 - harvard['sputum']\n",
    "\n",
    "# if 'sputum' is na and bring_up_sputum is < 4 set it to 1\n",
    "harvard.loc[harvard['sputum'].isna() & (harvard['bring_up_sputum'] < 4), 'sputum'] = 1\n",
    "\n",
    "# drop bring_up_sputum, how_difficult_sputum, how_much_sputum\n",
    "harvard = harvard.drop(columns=['bring_up_sputum', 'how_difficult_sputum', 'how_much_sputum'], axis=1)\n",
    "\n",
    "# reconstruct wheezing from sgrq05, bclinpt38, sgrq09\n",
    "harvard['wheezing'] = 1 - harvard['wheezing']\n",
    "\n",
    "# if wheezing is na and wheezing_attacks is < 4 set it to 1\n",
    "harvard.loc[harvard['wheezing'].isna() & (harvard['wheezing_attacks'] < 4), 'wheezing'] = 1\n",
    "harvard.loc[harvard['wheezing'].isna() & (harvard['wheeze_morning'] == 2 ), 'wheezing'] = 1\n",
    "harvard = harvard.drop(columns=['wheezing_attacks', 'wheeze_morning'], axis=1)\n",
    "\n",
    "# calculate 2 or more exacerbations last year variable\n",
    "harvard['two_exacerbations_last_year'] = harvard['prev_exacerb']\n",
    "harvard.loc[harvard['two_exacerbations_last_year'] <= 2, 'two_exacerbations_last_year'] = 0\n",
    "harvard.loc[harvard['two_exacerbations_last_year'] > 2, 'two_exacerbations_last_year'] = 1\n",
    "harvard = harvard.drop(columns=['prev_exacerb'], axis=1)\n",
    "# TODO maybe we have to use a different exacerbation definition\n",
    "\n",
    "# if patient was to the icu at least one time\n",
    "harvard['icu'] = harvard['icu_last_year']\n",
    "harvard.loc[harvard['icu'] == 1, 'icu'] = 0\n",
    "harvard.loc[harvard['icu'] > 1, 'icu'] = 1\n",
    "harvard = harvard.drop(columns=['icu_last_year'], axis=1)\n",
    "\n",
    "# reconstruction hospital from bclinpt26 (icu), bclinpt27 (icu), bclinpt24, bclinpt25\n",
    "harvard['hospitalization'] = harvard['hospitalizations_last_year']\n",
    "harvard.loc[harvard['hospitalization'] == 1, 'hospitalization'] = 0\n",
    "harvard.loc[harvard['hospitalization'] > 1, 'hospitalization'] = 1\n",
    "harvard.loc[harvard['hospitalization'].isna() & (harvard['icu'] == 1), 'hospitalization'] = 1\n",
    "harvard = harvard.drop(columns=['hospitalizations_last_year'], axis=1)\n",
    "# don't use daily activities as data is not sufficient\n",
    "\n",
    "# create smoker variable (everyone)\n",
    "harvard['smoker'] = 1\n",
    "\n",
    "# create inhaler variable\n",
    "harvard['inhaler'] = 0\n",
    "harvard.loc[(harvard['qvar'] == 1) | (harvard['azmacort'] == 1) | (harvard['flovent'] == 1)| (harvard['foradil'] == 1)| (harvard['serevent'] == 1)| (harvard['spiriva'] == 1)| (harvard['combivent'] == 1)| (harvard['atrovent'] == 1) | (harvard['proventil'] == 1)| (harvard['pulmicort'] == 1), 'inhaler'] = 1\n",
    "# drop inhaler columns\n",
    "harvard = harvard.drop(columns=['qvar', 'azmacort', 'flovent', 'foradil', 'serevent', 'spiriva', 'combivent', 'atrovent', 'proventil', 'pulmicort'], axis=1)\n",
    "\n",
    "# create pill for exa variable\n",
    "    # bclinpt43 = 2048, 1024, 4096, \n",
    "    # bclinpt44 any\n",
    "harvard['pill_for_exa'] = 0\n",
    "harvard.loc[(harvard['medication_copd'] == 2048) | (harvard['medication_copd'] == 1024)| (harvard['medication_copd'] == 4096), 'pill_for_exa'] = 1\n",
    "harvard = harvard.drop(columns=['medication_copd', 'other_antibiotic','other_medication', 'medication_copd_2', 'other_copd_medication' ], axis=1)\n",
    "\n",
    "# if percent_fev1_pred is na take percent_fev1_pred_2\n",
    "harvard['percent_fev1_pred'] = harvard['percent_fev1_pred'].fillna(harvard['percent_fev1_pred_2'])\n",
    "\n",
    "# TODO daily activities restricted var\n",
    "\n",
    "# drop all other not any more relevant vars\n",
    "harvard = harvard.drop(columns=['SRPSAT49_Bank', 'percent_fev1_pred_2', 'bclinra07', 'cancer', 'dyspnoea', 'fever', 'myocardial_infarct', 'stroke', 'fev1'])\n",
    "\n",
    "\n",
    "# get the baseline dataset\n",
    "unique_logins = harvard['login'].unique()\n",
    "# baseline dataframe has the same columns as the original dataset\n",
    "baseline = []\n",
    "for login in unique_logins:\n",
    "    # add the first row of the selection to the baseline dataset\n",
    "    baseline.append(harvard[harvard['login'] == login].iloc[0])\n",
    "# turn lists into dataframes but with columns from harvard dataset\n",
    "harvard = pd.DataFrame(baseline, columns=harvard.columns)\n",
    "harvard = harvard.drop('login', axis=1)\n",
    "\n",
    "# swap variable for which yes and no are reversed (yes = 0, no = 1)\n",
    "harvard['hypertension'] = 1 - harvard['hypertension']\n",
    "# harvard['fever'] = 1 - harvard['fever']\n",
    "harvard['heart_failure'] = 1- harvard['heart_failure']\n",
    "\n",
    "# subtract 1 of all target values and revert yes and no\n",
    "harvard['target'] = harvard['target'] - 1\n",
    "harvard['target'] = 1 - harvard['target']\n",
    "\n",
    "# calculate bmi from weight and height\n",
    "harvard['bmi'] = harvard['weight'] / (harvard['height'] / 100) ** 2\n",
    "harvard = harvard.drop(columns=['weight', 'height'])\n",
    "harvard = harvard.reindex(sorted(harvard.columns), axis=1)\n",
    "\n",
    "# print sorted columns\n",
    "# print(sorted(harvard.columns))\n",
    "# print(sorted(triage.columns))\n",
    "\n",
    "# # if prev_exacerb is 1 set it to 0\n",
    "# harvard.loc[harvard['prev_exacerb'] == 1, 'prev_exacerb'] = 0\n",
    "# # if prev_exacerb is above 1 set it to 1\n",
    "# harvard.loc[harvard['prev_exacerb'] > 1, 'prev_exacerb'] = 1\n",
    "# # plot_hist(harvard)\n",
    "\n",
    "##########\n",
    "# Missing Values & duplicates\n",
    "##########\n",
    "\n",
    "# drop the records where target is na\n",
    "harvard = harvard.dropna(subset=['target'])\n",
    "\n",
    "# print missing values per variable and total\n",
    "print(\"missing values per variable\")\n",
    "print(\"total records: \"+str(len(harvard)))\n",
    "print(harvard.isnull().sum())\n",
    "\n",
    "# drop all records where target is nan\n",
    "harvard = harvard.dropna(subset=['target'])\n",
    "\n",
    "numerical_vars = ['age', 'bmi','percent_fev1_pred']\n",
    "for var in numerical_vars:\n",
    "    harvard[var] = harvard[var].fillna(harvard[var].median())\n",
    "\n",
    "\n",
    "\n",
    "# impute gender, cancer, hypertension, diabetes, heart_failure, target with most frequent value\n",
    "categorical_vars = ['asthma','chronic_kidney_disease', 'cough', 'diabetes',  'gender', 'gold', 'heart_failure', 'hospitalization', 'hypertension', 'icu', 'inhaler', 'ischemic_heart_disease', 'mmrc', 'pill_for_exa', 'smoker', 'sputum', 'target', 'two_exacerbations_last_year', 'waking_up_at_night', 'wheezing'] # , 'fast_breathing',,, 'prev_exacerb' 'dyspnoea', 'cancer', 'myocardial_infarct', 'stroke', 'fever',\n",
    "for var in categorical_vars:\n",
    "    harvard[var] = harvard[var].fillna(harvard[var].mode()[0])\n",
    "\n",
    "\n",
    "# print(\"empty cells remaining in the dataset\")\n",
    "# print(harvard.isnull().sum().sum())\n",
    "\n",
    "# print(\"mv imputation\")\n",
    "\n",
    "# plot_hist(harvard)\n",
    "\n",
    "##########\n",
    "# Feature engineering\n",
    "############\n",
    "\n",
    "# print(\"feature engineering\")\n",
    "\n",
    "# plot_hist(harvard)\n",
    "\n",
    "##########\n",
    "# Normalization\n",
    "##########\n",
    "\n",
    "numeric_vars = ['age', 'bmi', 'mmrc', 'percent_fev1_pred']\n",
    "df_nr = harvard[numeric_vars]\n",
    "df_rest = harvard.drop(columns=numeric_vars)\n",
    "transf = MinMaxScaler(feature_range=(0, 1), copy=True).fit(df_nr)\n",
    "tmp = DataFrame(transf.transform(df_nr), index=harvard.index, columns=numeric_vars)\n",
    "harvard= concat([tmp, df_rest], axis=1)\n",
    "\n",
    "###########\n",
    "# Target variable\n",
    "###########\n",
    "\n",
    "\n",
    "# use smote to rebalance the harvard dataset in place\n",
    "# print(\"perform smote\")\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(harvard.drop(columns=['target']), harvard['target'])\n",
    "X_res['target'] = y_res\n",
    "harvard = X_res\n",
    "\n",
    "# use undersampling\n",
    "\n",
    "# # get number of underrespresented class 0\n",
    "# u = harvard['target'].value_counts().min()\n",
    "# u_label = harvard['target'].value_counts().idxmin()\n",
    "\n",
    "# # overrepresented class 1\n",
    "# o = harvard['target'].value_counts().max()\n",
    "# o_label = harvard['target'].value_counts().idxmax()\n",
    "\n",
    "# # add all underrepresented samples to a new dataframe\n",
    "# underrepresented = harvard[harvard['target'] == u_label]\n",
    "# # sample u number of overrepresented samples from the dataset\n",
    "# overrepresented = harvard[harvard['target'] == o_label].sample(n=u, random_state=42)\n",
    "# # concatenate underrepresented and overrepresented\n",
    "# harvard = pd.concat([underrepresented, overrepresented])\n",
    "# # plot_hist(harvard)\n",
    "# print(harvard['target'].value_counts())\n",
    "\n",
    "# sort the columns\n",
    "harvard = harvard.reindex(sorted(harvard.columns), axis=1)\n",
    "# convert all variables to int\n",
    "harvard = harvard.astype(int)\n",
    "\n",
    "# # save dataset\n",
    "harvard.to_csv('../harvard/data/triage_cv.csv', index=False, sep=';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Triage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender                                                         0\n",
      "Age                                                            0\n",
      "BMI                                                            0\n",
      "Baseline Dyspnea (MMRC)                                        0\n",
      "COPD Gold Stage                                               32\n",
      "Baseline FEV1                                                 32\n",
      "Baseline Heart Rate                                           30\n",
      "Baseline Pulse Ox                                             36\n",
      "Recent Worsening in Symptoms?                                  0\n",
      "% Controller Medication Taken Over Last Week                   0\n",
      "Short of Breath?                                               0\n",
      "Cough?                                                         0\n",
      "Wheezing?                                                      0\n",
      "Sputum?                                                        0\n",
      "Current Dyspnea (MMRC)                                         0\n",
      "Infection?                                                     0\n",
      "Respiratory Symptoms Wake You Up At Night More Than Usual?     0\n",
      "Symptom Severity (1-5)                                         0\n",
      "Baseline Heart Rate.1                                         30\n",
      "Current Heart Rate                                            24\n",
      "Baseline Pulse Ox.1                                           36\n",
      "Current Pulse Ox                                              31\n",
      "Baseline FEV1 (% Predicted)                                   32\n",
      "Current FEV1 (% Predicted)                                    29\n",
      "Current Temperature                                           29\n",
      "Exacerbation (Y/N)                                             0\n",
      "Height(cm)                                                     0\n",
      "Weight(kg)                                                     0\n",
      "Lives Alone                                                    0\n",
      "Visited ICU for COPD in Last Year                              0\n",
      "Congestive Heart Failure                                       0\n",
      "Anemia                                                         0\n",
      "Asthma                                                         0\n",
      "Pulmonary Hypertension                                         0\n",
      "High Blood Pressure                                            0\n",
      "2 or More Exacerbations In Last Year                           0\n",
      "Diabetes                                                       0\n",
      "Smoker                                                         0\n",
      "Coronary Artery Disease                                        0\n",
      "Acid Reflux                                                    0\n",
      "Chronic Kidney Disease                                         0\n",
      "Needs Help Performing Daily Activities                         0\n",
      "Long Term Oxygen User                                          0\n",
      "Hospitalized for COPD in Last Year                             0\n",
      "Pill for Controlling Exacerbations                             0\n",
      " Prescribed Inhaler                                            0\n",
      " Rescue Inhaler As Needed                                      0\n",
      "Prescribed Inhaler (Azithromycin or Roflumilast)               0\n",
      " rescue Inhaler As Needed.                                     0\n",
      "Rescue Inhaler Or Nebulizer As Needed For Breathing            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_2464\\3482200299.py:73: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  triage.loc[triage['Current Medication'].str.contains(medication, na=False), medication] = 1\n"
     ]
    }
   ],
   "source": [
    "triage = pd.read_excel('./triage/data/data.xlsx')\n",
    "\n",
    "# remove all empty rows\n",
    "triage = triage.dropna(how='all')\n",
    "\n",
    "# drop Alternate Diagnosis? (y/n), Final Triage 1 (1-4), Confidence 1 (%), Final Triage 2 (1-4), Confidence 2 (%), Highly Unrealistic Case (Y), Highly Uncertain (Y), Profile Severity (1-5)\n",
    "triage = triage.drop(columns=['Unnamed: 0', 'Alternate Diagnosis? (y/n)', 'Final Triage 1 (1-4)', 'Confidence 1 (%)', 'Final Triage 2 (1-4)', 'Confidence 2 (%)', 'Highly Unrealistic Case (Y)', 'Highly Uncertain (Y)', 'Profile Severity (1-5)'], axis=1)\n",
    "# reset index\n",
    "triage = triage.reset_index(drop=True)\n",
    "\n",
    "\n",
    "triage = triage.drop(triage.columns[triage.columns.get_loc('Exacerbation (Y/N)') + 1:], axis=1)\n",
    "# drop Vitals Severity (1-5)\n",
    "triage = triage.drop(columns=['Vitals Severity (1-5)'], axis=1)\n",
    "# convert all values where it say 'Unknown' to NaN\n",
    "triage = triage.replace('Unknown', np.nan)\n",
    "\n",
    "# turn Male into 1 and Female into 0\n",
    "triage = triage.replace('Male', 1)\n",
    "triage = triage.replace('Female', 0)\n",
    "\n",
    "# convert height from Height(ft) and Height(in) to Height(cm)\n",
    "triage['Height(cm)'] = triage['Height(ft)'] * 30.48 + triage['Height(in)'] * 2.54\n",
    "# drop Height(ft) and Height(in)\n",
    "triage = triage.drop(columns=['Height(ft)', 'Height(in)'], axis=1)\n",
    "\n",
    "# convert weight from Weight(lbs) to Weight(kg)\n",
    "triage['Weight(kg)'] = triage['Weight (lb)'] * 0.45359237\n",
    "# drop Weight(lbs)\n",
    "triage = triage.drop(columns=['Weight (lb)'], axis=1)\n",
    "\n",
    "# recalculate BMI for metric system\n",
    "triage['BMI'] = triage['Weight(kg)'] / (triage['Height(cm)'] / 100) ** 2\n",
    "\n",
    "# convert temperature from Temperature(F) to Temperature(C)\n",
    "triage['Current Temperature'] = (triage['Current Temperature'] - 32) * 5 / 9\n",
    "\n",
    "\n",
    "risk_factors = ()\n",
    "# add all unique values in columns Risk Factor 1-4 to risk_factors, make sure there are no duplicates\n",
    "for i in range(1, 5):\n",
    "    risk_factors += tuple(triage['Risk Factor ' + str(i)].unique())\n",
    "risk_factors = tuple(set(risk_factors))\n",
    "# remove NaN from risk_factors\n",
    "risk_factors = tuple(filter(lambda x: x == x, risk_factors))\n",
    "# create a column for each risk factor in risk_factors\n",
    "for risk_factor in risk_factors:\n",
    "    triage[risk_factor] = 0\n",
    "# set all values in the columns to 1 if the risk factor is present\n",
    "for i in range(1, 5):\n",
    "    for risk_factor in risk_factors:\n",
    "        triage.loc[triage['Risk Factor ' + str(i)] == risk_factor, risk_factor] = 1\n",
    "# drop Risk Factor 1-4\n",
    "triage = triage.drop(columns=['Risk Factor ' + str(i) for i in range(1, 5)], axis=1)\n",
    "\n",
    "medications = ()\n",
    "# split each value in 'Current Medication' at + and add the medication to the tuple if it is not already in there\n",
    "for medication in triage['Current Medication']:\n",
    "    # if the value is not empty\n",
    "    if medication == medication:\n",
    "        # split the value at + and add the medication to the tuple if it is not already in there\n",
    "        for med in str(medication).split('+'):\n",
    "            if med not in medications:\n",
    "                medications += (med,)\n",
    "\n",
    "\n",
    "\n",
    "# create a column for each medication in medications\n",
    "for medication in medications:\n",
    "    triage[medication] = 0\n",
    "# set all values in the columns to 1 if the medication is present\n",
    "for medication in medications:\n",
    "    triage.loc[triage['Current Medication'].str.contains(medication, na=False), medication] = 1\n",
    "# drop Current Medication\n",
    "triage = triage.drop(columns=['Current Medication'], axis=1)\n",
    "\n",
    "# turn Baseline Dyspnea (MMRC) into the number that the value contains\n",
    "triage['Baseline Dyspnea (MMRC)'] = triage['Baseline Dyspnea (MMRC)'].str.extract('(\\d+)')\n",
    "# turn COPD Gold Stage into the number that the value contains\n",
    "triage['COPD Gold Stage'] = triage['COPD Gold Stage'].str.extract('(\\d+)')\n",
    "# turn Recent Worsening in Symptoms? into categorical values for each unique values\n",
    "triage['Recent Worsening in Symptoms?'] = triage['Recent Worsening in Symptoms?'].astype('category').cat.codes\n",
    "# turn % Controller Medication Taken Over Last Week into categorical values for each unique values\n",
    "triage['% Controller Medication Taken Over Last Week'] = triage['% Controller Medication Taken Over Last Week'].astype('category').cat.codes\n",
    "# turn Short of Breath? into categorical values for each unique values\n",
    "triage['Short of Breath?'] = triage['Short of Breath?'].astype('category').cat.codes\n",
    "# turn Cough? into categorical values for each unique values\n",
    "triage['Cough?'] = triage['Cough?'].astype('category').cat.codes\n",
    "# turn Sputum? into categorical values for each unique values\n",
    "triage['Sputum?'] = triage['Sputum?'].astype('category').cat.codes\n",
    "# turn Wheezing? into categorical values for each unique values\n",
    "triage['Wheezing?'] = triage['Wheezing?'].astype('category').cat.codes\n",
    "\n",
    "# turn Current Dyspnea (MMRC) into the number that the value contains\n",
    "triage['Current Dyspnea (MMRC)'] = triage['Current Dyspnea (MMRC)'].str.extract('(\\d+)')\n",
    "\n",
    "# turn all values that contain 'No' into 0 and all values that contain 'Yes' into 1\n",
    "triage = triage.replace('No', 0)\n",
    "triage = triage.replace('Yes', 1)\n",
    "triage = triage.replace('Y', 1)\n",
    "triage = triage.replace('y', 0)\n",
    "triage = triage.replace('N', 0)\n",
    "\n",
    "# print missing values\n",
    "print(triage.isnull().sum())\n",
    "\n",
    "categorical_vars = ['COPD Gold Stage']\n",
    "# impute using mode\n",
    "for var in categorical_vars:\n",
    "    triage[var].fillna(triage[var].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "numerical_vars = ['Baseline FEV1', 'Baseline Heart Rate', 'Baseline Pulse Ox', 'Baseline Heart Rate.1', 'Baseline Pulse Ox.1', 'Current Heart Rate', 'Current Pulse Ox', 'Current Temperature', 'Current FEV1 (% Predicted)', 'Baseline FEV1 (% Predicted)']\n",
    "\n",
    "# impute using median\n",
    "for var in numerical_vars:\n",
    "    triage[var].fillna(triage[var].median(), inplace=True)\n",
    "\n",
    "# create fever variable\n",
    "# triage['fever'] = 0\n",
    "# triage.loc[triage['Current Temperature'] > 38, 'fever'] = 1\n",
    "# # drop Current Temperature\n",
    "# triage = triage.drop(columns=['Current Temperature'], axis=1)\n",
    "\n",
    "# scaling\n",
    "scaler = MinMaxScaler()\n",
    "target = triage['Exacerbation (Y/N)']\n",
    "triage = triage.drop(columns=['Exacerbation (Y/N)'], axis=1)\n",
    "triage = pd.DataFrame(scaler.fit_transform(triage), columns=triage.columns)\n",
    "triage['Exacerbation (Y/N)'] = target\n",
    "\n",
    "# target variable\n",
    "# print(triage['Exacerbation (Y/N)'].value_counts())\n",
    "# balance using smote\n",
    "sm = SMOTE(random_state=42)\n",
    "X = triage.drop(columns=['Exacerbation (Y/N)'], axis=1)\n",
    "y = triage['Exacerbation (Y/N)']\n",
    "X, y = sm.fit_resample(X, y)\n",
    "triage = X\n",
    "triage['Exacerbation (Y/N)'] = y\n",
    "\n",
    "# without current temperature for now\n",
    "\n",
    "relevant_vars = [\n",
    "    'Age', \n",
    "    'Gender', \n",
    "    'BMI', \n",
    "    'Baseline Dyspnea (MMRC)', \n",
    "    'COPD Gold Stage', \n",
    "    'Cough?', 'Sputum?', 'Wheezing?', \n",
    "    'Baseline FEV1', \n",
    "    # 'Current FEV1 (% Predicted)', \n",
    "    'Baseline FEV1 (% Predicted)', \n",
    "    'Exacerbation (Y/N)', \n",
    "    'Respiratory Symptoms Wake You Up At Night More Than Usual?', \n",
    "    '2 or More Exacerbations In Last Year', \n",
    "    'High Blood Pressure', \n",
    "    'Coronary Artery Disease', \n",
    "    'Congestive Heart Failure', \n",
    "    'Asthma', \n",
    "    'Needs Help Performing Daily Activities', \n",
    "    'Chronic Kidney Disease',  \n",
    "    'Diabetes', \n",
    "    'Visited ICU for COPD in Last Year', \n",
    "    'Hospitalized for COPD in Last Year', \n",
    "    'Smoker', \n",
    "    'Pill for Controlling Exacerbations ', \n",
    "    ' Prescribed Inhaler ', \n",
    "    ' Rescue Inhaler As Needed', \n",
    "    'Prescribed Inhaler (Azithromycin or Roflumilast) ', \n",
    "    ' rescue Inhaler As Needed.', \n",
    "    'Rescue Inhaler Or Nebulizer As Needed For Breathing', ]\n",
    "\n",
    "triage = triage[relevant_vars]\n",
    "\n",
    "# rename vars\n",
    "triage = triage.rename(columns={\n",
    "    \"Age\":\"age\", \n",
    "    \"Gender\":\"gender\", \n",
    "    \"BMI\":\"bmi\", \n",
    "    \"Baseline Dyspnea (MMRC)\":\"mmrc\", \n",
    "    \"COPD Gold Stage\":\"gold\", \n",
    "    \"Cough?\":\"cough\", \n",
    "    \"Sputum?\":\"sputum\", \n",
    "    \"Wheezing?\":\"wheezing\", \n",
    "    \"Baseline FEV1\":\"fev1\", \n",
    "    \"Current Temperature\":\"temperature\", \n",
    "    \"Current FEV1 (% Predicted)\":\"percent_fev1_pred_current\", \n",
    "    \"Baseline FEV1 (% Predicted)\":\"percent_fev1_pred\", \n",
    "    \"Exacerbation (Y/N)\":\"target\", \n",
    "    \"Respiratory Symptoms Wake You Up At Night More Than Usual?\":\"waking_up_at_night\", \n",
    "    \"2 or More Exacerbations In Last Year\":\"two_exacerbations_last_year\", \n",
    "    \"High Blood Pressure\":\"hypertension\", \n",
    "    \"Coronary Artery Disease\":\"ischemic_heart_disease\", \n",
    "    \"Congestive Heart Failure\":\"heart_failure\", \n",
    "    \"Asthma\":\"asthma\", \n",
    "    \"Needs Help Performing Daily Activities\":\"daily_activities_restricted\", \n",
    "    \"Chronic Kidney Disease\":\"chronic_kidney_disease\",  \n",
    "    \"Diabetes\":\"diabetes\", \n",
    "    \"Visited ICU for COPD in Last Year\":\"icu\", \n",
    "    \"Hospitalized for COPD in Last Year\":\"hospitalization\", \n",
    "    \"Smoker\":\"smoker\", \n",
    "    \"Pill for Controlling Exacerbations \":\"pill_for_exa\", \n",
    "    \" Prescribed Inhaler \":\"medication_inhaler\", \n",
    "    \" Rescue Inhaler As Needed\":\"medication_rescue_inhaler\", \n",
    "    \"Prescribed Inhaler (Azithromycin or Roflumilast) \":\"medication_azithromycin_roflumilast\", \n",
    "    \" rescue Inhaler As Needed.\":\"medication_rescue_inhaler_as_needed\", \n",
    "    \"Rescue Inhaler Or Nebulizer As Needed For Breathing\":\"medication_rescue_inhaler_or_nebulizer\"})\n",
    "\n",
    "# perform some feature engineering\n",
    "triage[\"inhaler\"] = 0\n",
    "if triage[\"medication_inhaler\"].any() == 1 or triage[\"medication_rescue_inhaler\"].any() == 1 or triage[\"medication_rescue_inhaler_as_needed\"].any() == 1 or triage[\"medication_rescue_inhaler_or_nebulizer\"].any() == 1 or triage[\"medication_azithromycin_roflumilast\"].any() == 1:\n",
    "    triage[\"inhaler\"] = 1\n",
    "\n",
    "# drop unnecessary columns\n",
    "triage = triage.drop(columns=[\"medication_inhaler\", \"medication_rescue_inhaler\", \"medication_rescue_inhaler_as_needed\", \"medication_rescue_inhaler_or_nebulizer\", \"medication_azithromycin_roflumilast\", \"daily_activities_restricted\", 'fev1'], axis=1)\n",
    "\n",
    "# triage['fever'] = 0\n",
    "# triage.loc[triage['temperature'] > 38, 'fever'] = 1\n",
    "\n",
    "# sort the columns\n",
    "triage = triage.reindex(sorted(triage.columns), axis=1)\n",
    "\n",
    "# export as harvard_cv\n",
    "triage.to_csv(\"../triage/data/harvard_cv.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is harvard, 1 is triage\n",
    "\n",
    "\n",
    "# create train set from triage\n",
    "harvard_samples = harvard.sample(frac=0.5, random_state=42)\n",
    "# give all harvard samples the label [0,1]\n",
    "harvard_samples[\"dataset\"] = 0\n",
    "triage_samples = triage.sample(frac=0.5, random_state=42)\n",
    "# give all triage samples the label [1,0]\n",
    "triage_samples[\"dataset\"] = 1\n",
    "train = pd.concat([triage_samples.drop(columns=[\"dataset\"]), harvard_samples.drop(columns=[\"dataset\"])])\n",
    "train = train.reset_index(drop=True).to_numpy()\n",
    "test = pd.concat([triage_samples[\"dataset\"], harvard_samples[\"dataset\"]])\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train, batch_size=batch_size, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Pytorch discriminator that provides the probability that a sample belongs to the harvard dataset (0) or the triage dataset (1)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(23, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n",
    "discriminator = Discriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Pytorch generator that generates a sample (23 variables) that is either from the triage or harvard dataset\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 24)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_epochs = 300\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 2.0000, 1.0000,\n",
      "         0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1707, 0.0000, 0.4548, 0.0000, 0.5000, 1.0000, 1.0000, 0.6667, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.4744, 0.0000, 0.0000,\n",
      "         1.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 3.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 3.0000, 1.0000],\n",
      "        [0.1463, 1.0000, 0.5420, 0.0000, 0.0000, 0.0000, 0.0000, 0.6667, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.3974, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.9756, 0.0000, 0.4984, 0.0000, 0.5000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.5000, 0.8333, 0.0000, 0.0000,\n",
      "         0.3333, 1.0000, 0.0000, 0.0000, 0.5000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 3.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 1.0000, 0.0000, 2.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 2.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 2.0000, 1.0000],\n",
      "        [0.3659, 0.0000, 0.6674, 0.0000, 0.0000, 0.0000, 0.0000, 0.6667, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.4231, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3271, 0.0000, 0.1816, 0.0000, 0.0000, 0.0000, 1.0000, 0.8916, 0.0000,\n",
      "         0.6747, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.3017, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 2.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 2.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 4.0000, 1.0000,\n",
      "         0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 3.0000, 0.0000],\n",
      "        [0.5366, 0.0000, 0.4966, 0.0000, 0.5000, 0.0000, 0.0000, 0.6667, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.2500, 0.3846, 1.0000, 0.0000,\n",
      "         0.6667, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.3607, 0.0000, 0.3320, 0.0000, 0.6625, 0.3375, 1.0000, 0.3333, 0.0000,\n",
      "         0.3375, 0.0000, 0.0000, 1.0000, 0.0000, 0.1687, 0.5595, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.6625],\n",
      "        [0.1231, 0.0000, 0.2021, 0.0000, 0.9548, 0.0000, 0.0000, 0.6817, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.9661, 0.4202, 0.0000, 0.9548,\n",
      "         0.6817, 0.0000, 0.0000, 0.9548, 0.0000],\n",
      "        [0.3902, 0.0000, 0.2938, 0.0000, 1.0000, 0.0000, 0.0000, 0.3333, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.5000, 0.5256, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m# Training the discriminator\u001b[39;00m\n\u001b[0;32m     15\u001b[0m discriminator\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 16\u001b[0m output_discriminator \u001b[39m=\u001b[39m discriminator(all_samples)\n\u001b[0;32m     18\u001b[0m loss_discriminator \u001b[39m=\u001b[39m loss_function(\n\u001b[0;32m     19\u001b[0m     output_discriminator, all_samples_labels)\n\u001b[0;32m     21\u001b[0m loss_discriminator\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[56], line 20\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 20\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for n, real_samples in enumerate(train_loader):\n",
    "        print(real_samples)\n",
    "        # Data for training the discriminator\n",
    "        real_samples_labels = torch.ones((batch_size, 1))\n",
    "        latent_space_samples = torch.randn((batch_size, 2))\n",
    "        # generated_samples = generator(latent_space_samples)\n",
    "        generated_samples_labels = torch.zeros((batch_size, 1))\n",
    "        # all_samples = torch.cat((real_samples, generated_samples))\n",
    "        all_samples_labels = real_samples_labels\n",
    "        all_samples = real_samples\n",
    "        \n",
    "\n",
    "        # Training the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        output_discriminator = discriminator(all_samples)\n",
    "\n",
    "        loss_discriminator = loss_function(\n",
    "            output_discriminator, all_samples_labels)\n",
    "\n",
    "        loss_discriminator.backward()\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "\n",
    "        # # Data for training the generator\n",
    "        # latent_space_samples = torch.randn((batch_size, 2))\n",
    "\n",
    "        # # Training the generator\n",
    "        # generator.zero_grad()\n",
    "        # generated_samples = generator(latent_space_samples)\n",
    "        # output_discriminator_generated = discriminator(generated_samples)\n",
    "\n",
    "        # loss_generator = loss_function(\n",
    "        #     output_discriminator_generated, real_samples_labels\n",
    "        # )\n",
    "\n",
    "        # loss_generator.backward()\n",
    "        # optimizer_generator.step()\n",
    "\n",
    "\n",
    "        # Show loss\n",
    "\n",
    "        if epoch % 10 == 0 and n == batch_size - 1:\n",
    "            print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n",
    "            # print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
